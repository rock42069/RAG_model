{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "o37CzGJcEdqt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2e68058-4ebd-4d73-d11c-76b205fec59d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-cloud-documentai in /usr/local/lib/python3.10/dist-packages (2.21.1)\n",
            "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-documentai) (2.11.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-documentai) (1.23.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-cloud-documentai) (3.20.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-documentai) (1.62.0)\n",
            "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-documentai) (2.17.3)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-documentai) (2.31.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-documentai) (1.60.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-documentai) (1.48.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-documentai) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-documentai) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-documentai) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-documentai) (4.9)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-documentai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-documentai) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-documentai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-documentai) (2023.11.17)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-documentai) (0.5.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install google-cloud-documentai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import necessary files\n",
        "from google.colab import auth\n",
        "from typing import Optional, Sequence\n",
        "from google.api_core.client_options import ClientOptions\n",
        "from google.cloud import documentai\n",
        "import sys"
      ],
      "metadata": {
        "id": "vLrJ5jsvKOXC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Authenticate with Google Cloud\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "XaE00T3qKaKF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#this info will be extracted from google cloud\n",
        "project_id = \"attendanceextractor\"\n",
        "location = \"us\"                                             # Format is \"us\" or \"eu\"\n",
        "processor_id = \"12bf41b9e4b98255\"                           # Create processor before running sample\n",
        "processor_version = \"rc\"                                    # Refer to https://cloud.google.com/document-ai/docs/manage-processor-versions for more information\n",
        "file_path = \"/content/Copy of MAHENDRAGARH_NEO_121023_4.jpeg\"\n",
        "mime_type = \"image/jpeg\"                                    # Refer to https://cloud.google.com/document-ai/docs/file-types for supported file types"
      ],
      "metadata": {
        "id": "hpIbe-76Ke-4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#changed the return type to dict i.e. 'document' is a dictionary datatype\n",
        "def process_document_form_sample(\n",
        "    project_id: str,\n",
        "    location: str,\n",
        "    processor_id: str,\n",
        "    processor_version: str,\n",
        "    file_path: str,\n",
        "    mime_type: str,\n",
        ") -> dict:\n",
        "\n",
        "    # Online processing request to Document AI\n",
        "    document = process_document(\n",
        "        project_id, location, processor_id, processor_version, file_path, mime_type\n",
        "    )\n",
        "\n",
        "    # Read the table and form fields output from the processor\n",
        "    # The form processor also contains OCR data. For more information\n",
        "    # on how to parse OCR data please see the OCR sample.\n",
        "\n",
        "    text = document.text\n",
        "    # print(f\"Full document text: {repr(text)}\\n\")\n",
        "    print(f\"There are {len(document.pages)} page(s) in this document.\")\n",
        "    for page in document.pages:\n",
        "      print(f\"\\n\\n**** Page {page.page_number} ****\")\n",
        "\n",
        "      #print(f\"\\nFound {len(page.tables)} table(s):\")\n",
        "      for table in page.tables:\n",
        "        num_columns = len(table.header_rows[0].cells)\n",
        "        num_rows = len(table.body_rows)\n",
        "        #print(f\"Table with {num_columns} columns and {num_rows} rows:\")\n",
        "\n",
        "        # Print header rows only if it's the first table on the page\n",
        "        if table == page.tables[0]:\n",
        "            print(\"Columns:\")\n",
        "            header_row_text = \"\"\n",
        "            for cell in table.header_rows[0].cells:\n",
        "                cell_text = layout_to_text(cell.layout, text)\n",
        "                header_row_text += f\"{repr(cell_text.strip())} | \" if cell_text.strip() else \"'' | \"\n",
        "            print(header_row_text)\n",
        "\n",
        "        # Print body rows\n",
        "        #print(\"Table body data:\")\n",
        "        for table_row in table.body_rows:\n",
        "            row_text = \"\"\n",
        "            for cell in table_row.cells:\n",
        "                cell_text = layout_to_text(cell.layout, text)\n",
        "                row_text += f\"{repr(cell_text.strip())} | \"\n",
        "\n",
        "            # Output format for each row\n",
        "            formatted_output = {\n",
        "                header_cell.strip(): row_cell.strip()\n",
        "                for header_cell, row_cell in zip(header_row_text.split('|'), row_text.split('|'))\n",
        "            }\n",
        "\n",
        "            # Print formatted output with line breaks\n",
        "            print(\"\\n\".join([f\"{key}: {value}\" for key, value in formatted_output.items()]))\n",
        "\n",
        "        for field in page.form_fields:\n",
        "            name = layout_to_text(field.field_name, text)\n",
        "            value = layout_to_text(field.field_value, text)\n",
        "            print(f\"    * {repr(name.strip())}: {repr(value.strip())}\")\n",
        "\n",
        "        return document"
      ],
      "metadata": {
        "id": "xfAMHygZZ2Dq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions for processing extracted text"
      ],
      "metadata": {
        "id": "Wa5GuClwmreY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_table_rows(\n",
        "    table_rows: Sequence[documentai.Document.Page.Table.TableRow], text: str\n",
        ") -> None:\n",
        "    for table_row in table_rows:\n",
        "        row_text = \"\"\n",
        "        for cell in table_row.cells:\n",
        "            cell_text = layout_to_text(cell.layout, text)\n",
        "            row_text += f\"{repr(cell_text.strip())} | \"\n",
        "        print(row_text)"
      ],
      "metadata": {
        "id": "pJjlDg0hLX7S"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#this function is not called in the current code, but can be used to calculate confidence scores to see how our model performs\n",
        "def print_entity(entity: documentai.Document.Entity) -> None:\n",
        "    # Fields detected. For a full list of fields for each processor see\n",
        "    # the processor documentation:\n",
        "    # https://cloud.google.com/document-ai/docs/processors-list\n",
        "    key = entity.type_\n",
        "\n",
        "    # Some other value formats in addition to text are availible\n",
        "    # e.g. dates: `entity.normalized_value.date_value.year`\n",
        "    text_value = entity.text_anchor.content\n",
        "    confidence = entity.confidence\n",
        "    normalized_value = entity.normalized_value.text\n",
        "    print(f\"    * {repr(key)}: {repr(text_value)}({confidence:.1%} confident)\")\n",
        "\n",
        "    if normalized_value:\n",
        "        print(f\"    * Normalized Value: {repr(normalized_value)}\")"
      ],
      "metadata": {
        "id": "_1m6lkq4Lbsj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_document(\n",
        "    project_id: str,\n",
        "    location: str,\n",
        "    processor_id: str,\n",
        "    processor_version: str,\n",
        "    file_path: str,\n",
        "    mime_type: str,\n",
        "    process_options: Optional[documentai.ProcessOptions] = None,\n",
        ") -> documentai.Document:\n",
        "    # You must set the `api_endpoint` if you use a location other than \"us\".\n",
        "    client = documentai.DocumentProcessorServiceClient(\n",
        "        client_options=ClientOptions(\n",
        "            api_endpoint=f\"{location}-documentai.googleapis.com\"\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # The full resource name of the processor version, e.g.:\n",
        "    # `projects/{project_id}/locations/{location}/processors/{processor_id}/processorVersions/{processor_version_id}`\n",
        "    # You must create a processor before running this sample.\n",
        "    name = client.processor_version_path(\n",
        "        project_id, location, processor_id, processor_version\n",
        "    )\n",
        "\n",
        "    # Read the file into memory\n",
        "    with open(file_path, \"rb\") as image:\n",
        "        image_content = image.read()\n",
        "\n",
        "    # Configure the process request\n",
        "    request = documentai.ProcessRequest(\n",
        "        name=name,\n",
        "        raw_document=documentai.RawDocument(content=image_content, mime_type=mime_type),\n",
        "        # Only supported for Document OCR processor\n",
        "        process_options=process_options,\n",
        "    )\n",
        "\n",
        "    result = client.process_document(request=request)\n",
        "\n",
        "    # For a full list of `Document` object attributes, reference this page:\n",
        "    # https://cloud.google.com/document-ai/docs/reference/rest/v1/Document\n",
        "    return result.document"
      ],
      "metadata": {
        "id": "HgaB1t5OLfK5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def layout_to_text(layout: documentai.Document.Page.Layout, text: str) -> str:\n",
        "    \"\"\"\n",
        "    Document AI identifies text in different parts of the document by their\n",
        "    offsets in the entirety of the document\"s text. This function converts\n",
        "    offsets to a string.\n",
        "    \"\"\"\n",
        "    # If a text segment spans several lines, it will\n",
        "    # be stored in different text segments.\n",
        "    return \"\".join(\n",
        "        text[int(segment.start_index) : int(segment.end_index)]\n",
        "        for segment in layout.text_anchor.text_segments\n",
        "    )"
      ],
      "metadata": {
        "id": "eUbYvDJILifO"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: #run process_document_form_sample\n",
        "#to see the output format\n",
        "doc_output = process_document_form_sample(\n",
        "                     project_id, location, processor_id, processor_version, file_path, mime_type,)"
      ],
      "metadata": {
        "id": "l2IH4FC9Lk1_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6148ad88-7f75-4064-aa46-a6c3d91e0290"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 page(s) in this document.\n",
            "\n",
            "\n",
            "**** Page 1 ****\n",
            "Columns:\n",
            "'SESSION\\nDATE' | 'SESSION\\nLOCATION' | 'SESSION\\nCONDUCTED\\nBY NAME' | 'ANC' | 'CLASS' | 'CLASS TYPE\\nSNCU' | 'NBSU' | 'PEOPLE\\nTRAINED' | 'PHOTO\\nSENT' | \n",
            "'SESSION\\nDATE': '9/08/23'\n",
            "'SESSION\\nLOCATION': 'PNC ward'\n",
            "'SESSION\\nCONDUCTED\\nBY NAME': 'Mlo- Sarmila'\n",
            "'ANC': ''\n",
            "'CLASS': ''\n",
            "'CLASS TYPE\\nSNCU': ''\n",
            "'NBSU': ''\n",
            "'PEOPLE\\nTRAINED': '42'\n",
            "'PHOTO\\nSENT': 'L'\n",
            ": \n",
            "'SESSION\\nDATE': '11/8/23'\n",
            "'SESSION\\nLOCATION': 'PNC Ward'\n",
            "'SESSION\\nCONDUCTED\\nBY NAME': 'No.\\nReena\\nsapna'\n",
            "'ANC': 'COO'\n",
            "'CLASS': '~'\n",
            "'CLASS TYPE\\nSNCU': ''\n",
            "'NBSU': ''\n",
            "'PEOPLE\\nTRAINED': ''\n",
            "'PHOTO\\nSENT': ''\n",
            ": \n",
            "'SESSION\\nDATE': '12/8/23'\n",
            "'SESSION\\nLOCATION': 'PNC ward'\n",
            "'SESSION\\nCONDUCTED\\nBY NAME': 'Mo-Reeng'\n",
            "'ANC': ''\n",
            "'CLASS': ''\n",
            "'CLASS TYPE\\nSNCU': ''\n",
            "'NBSU': '00'\n",
            "'PEOPLE\\nTRAINED': '30'\n",
            "'PHOTO\\nSENT': ''\n",
            ": \n",
            "'SESSION\\nDATE': '14/8/2'\n",
            "'SESSION\\nLOCATION': 'PNC ward'\n",
            "'SESSION\\nCONDUCTED\\nBY NAME': 'Mo- Lagwanti\\nPinki, Reena'\n",
            "'ANC': ''\n",
            "'CLASS': ''\n",
            "'CLASS TYPE\\nSNCU': ''\n",
            "'NBSU': ''\n",
            "'PEOPLE\\nTRAINED': '48'\n",
            "'PHOTO\\nSENT': ''\n",
            ": \n",
            "'SESSION\\nDATE': '16/8/23'\n",
            "'SESSION\\nLOCATION': 'PMCward'\n",
            "'SESSION\\nCONDUCTED\\nBY NAME': 'Sharmib,\\nلسلف'\n",
            "'ANC': ''\n",
            "'CLASS': ''\n",
            "'CLASS TYPE\\nSNCU': ''\n",
            "'NBSU': ''\n",
            "'PEOPLE\\nTRAINED': '255er\\n46'\n",
            "'PHOTO\\nSENT': ''\n",
            ": \n",
            "'SESSION\\nDATE': '21/8/23'\n",
            "'SESSION\\nLOCATION': 'PNC ward'\n",
            "'SESSION\\nCONDUCTED\\nBY NAME': 'Sharmila\\nReang...'\n",
            "'ANC': ''\n",
            "'CLASS': 'L'\n",
            "'CLASS TYPE\\nSNCU': ''\n",
            "'NBSU': ''\n",
            "'PEOPLE\\nTRAINED': '45'\n",
            "'PHOTO\\nSENT': ''\n",
            ": \n",
            "'SESSION\\nDATE': '22/8/23'\n",
            "'SESSION\\nLOCATION': 'PNC ward'\n",
            "'SESSION\\nCONDUCTED\\nBY NAME': 'Sujata.'\n",
            "'ANC': ''\n",
            "'CLASS': ''\n",
            "'CLASS TYPE\\nSNCU': ''\n",
            "'NBSU': ''\n",
            "'PEOPLE\\nTRAINED': '42'\n",
            "'PHOTO\\nSENT': ''\n",
            ": \n",
            "'SESSION\\nDATE': '23/8/23'\n",
            "'SESSION\\nLOCATION': 'ANG'\n",
            "'SESSION\\nCONDUCTED\\nBY NAME': 'Safana.'\n",
            "'ANC': ''\n",
            "'CLASS': ''\n",
            "'CLASS TYPE\\nSNCU': ''\n",
            "'NBSU': ''\n",
            "'PEOPLE\\nTRAINED': '40'\n",
            "'PHOTO\\nSENT': ''\n",
            ": \n",
            "'SESSION\\nDATE': '24/8/23'\n",
            "'SESSION\\nLOCATION': 'New'\n",
            "'SESSION\\nCONDUCTED\\nBY NAME': 'vlo Kavita\\nReena'\n",
            "'ANC': ''\n",
            "'CLASS': ''\n",
            "'CLASS TYPE\\nSNCU': ''\n",
            "'NBSU': ''\n",
            "'PEOPLE\\nTRAINED': '40'\n",
            "'PHOTO\\nSENT': ''\n",
            ": \n",
            "    * 'Facility Name:': 'GH NNL M/garh'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Raw txt file"
      ],
      "metadata": {
        "id": "kIYUpU1F4t9Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#store the original results in a text file\n",
        "\n",
        "# Redirect stdout to a file\n",
        "with open(\"text_output.txt\", \"w\") as f:\n",
        "    sys.stdout = f  # This will redirect print statements to the file\n",
        "\n",
        "    #processing and printing the document\n",
        "    process_document_form_sample(\n",
        "      project_id,\n",
        "      location,\n",
        "      processor_id,\n",
        "      processor_version,\n",
        "      file_path,\n",
        "      mime_type,\n",
        "    )\n",
        "\n",
        "    # Restore stdout\n",
        "    sys.stdout = sys.__stdout__\n",
        "\n",
        "# Print a message indicating the file has been created\n",
        "print(\"Output has been saved to text_output.txt\")\n"
      ],
      "metadata": {
        "id": "-cNQMj2nTNyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#To convert doc_output to dict format\n",
        "\n",
        "def convert_document_to_dictionary(document):\n",
        "\n",
        "    converted_dict = {\"pages\": []}\n",
        "\n",
        "    for page in document.pages:\n",
        "        page_dict = {\n",
        "            \"page_number\": page.page_number,\n",
        "            \"tables\": [],\n",
        "            \"form_fields\": [],\n",
        "        }\n",
        "\n",
        "        for table in page.tables:\n",
        "            table_dict = {\n",
        "                \"columns\": [layout_to_text(cell.layout, document.text).strip() for cell in table.header_rows[0].cells],\n",
        "                \"rows\": [\n",
        "                    [layout_to_text(cell.layout, document.text).strip() for cell in row.cells]\n",
        "                    for row in table.body_rows\n",
        "                ],\n",
        "            }\n",
        "            page_dict[\"tables\"].append(table_dict)\n",
        "\n",
        "        for field in page.form_fields:\n",
        "            name = layout_to_text(field.field_name, document.text).strip()\n",
        "            value = layout_to_text(field.field_value, document.text).strip()\n",
        "            page_dict[\"form_fields\"].append({name: value})\n",
        "\n",
        "        converted_dict[\"pages\"].append(page_dict)\n",
        "\n",
        "    return converted_dict\n"
      ],
      "metadata": {
        "id": "M7Fc47NMcKnr"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converted_output is doc_output in dictionary format\n",
        "converted_output = convert_document_to_dictionary(doc_output)\n",
        "\n",
        "print(converted_output)"
      ],
      "metadata": {
        "id": "Cp7jSr7H7JPV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de3d18d0-c7c0-4229-82a9-ca4ce5e70075"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'pages': [{'page_number': 1, 'tables': [{'columns': ['SESSION\\nDATE', 'SESSION\\nLOCATION', 'SESSION\\nCONDUCTED\\nBY NAME', 'ANC', 'CLASS', 'CLASS TYPE\\nSNCU', 'NBSU', 'PEOPLE\\nTRAINED', 'PHOTO\\nSENT'], 'rows': [['9/08/23', 'PNC ward', 'Mlo- Sarmila', '', '', '', '', '42', 'L'], ['11/8/23', 'PNC Ward', 'No.\\nReena\\nsapna', 'COO', '~', '', '', '', ''], ['12/8/23', 'PNC ward', 'Mo-Reeng', '', '', '', '00', '30', ''], ['14/8/2', 'PNC ward', 'Mo- Lagwanti\\nPinki, Reena', '', '', '', '', '48', ''], ['16/8/23', 'PMCward', 'Sharmib,\\nلسلف', '', '', '', '', '255er\\n46', ''], ['21/8/23', 'PNC ward', 'Sharmila\\nReang...', '', 'L', '', '', '45', ''], ['22/8/23', 'PNC ward', 'Sujata.', '', '', '', '', '42', ''], ['23/8/23', 'ANG', 'Safana.', '', '', '', '', '40', ''], ['24/8/23', 'New', 'vlo Kavita\\nReena', '', '', '', '', '40', '']]}, {'columns': ['25/8/20', 'P.NC', 'Roly wants\\n180 Kavit', '45', ''], 'rows': [['26/8/23', 'P.N.C.', 'Mo Lawanti\\nAnita.', '42', ''], ['30/8/23', 'PMC', 'Laranti\\nAle\\nPoonam', '327\\nчо', ''], ['31/8/27', 'PNC', 'N/- SujataKavita', '43', ''], ['1/09/23', 'PNC', 'Nh-Shamile', '', ''], ['', '', 'Lajwanti\\nPoonam', '383\\n38', ''], ['02/09/27', 'PMC', 'Na Nirmala\\n·Poo ham', '46', ''], ['04/9/23', 'Pnc', 'Sharmil\\nNo.\\nfornen.', '42', ''], ['4/9/23', 'PNC', 'W/o Reena', '36', '✓'], ['5/9/23', 'PNC', 'N/o Reena', '40', ''], ['5/9/23', 'PNC', 'Nlo Reenal\\nSharmila', '38', '']]}], 'form_fields': [{'Facility Name:': 'GH NNL M/garh'}]}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#convert dictionary to json type keeping all the columns as extracted\n",
        "\n",
        "def json_structure(dictionary):\n",
        "    structured_output = {\"pages\": []}\n",
        "\n",
        "    for page in dictionary['pages']:\n",
        "        current_page = {'page_number': page['page_number'], 'tables': []}\n",
        "\n",
        "        for table_index, table in enumerate(page['tables']):\n",
        "            if table_index == 0:\n",
        "                current_page['tables'].append({'columns': table['columns'], 'rows': []})\n",
        "            else:\n",
        "                current_page['tables'][0]['rows'].append(table['columns'])\n",
        "\n",
        "            for row in table['rows']:\n",
        "                current_page['tables'][0]['rows'].append(row)\n",
        "\n",
        "        current_page['form_fields'] = page['form_fields']\n",
        "        structured_output['pages'].append(current_page)\n",
        "\n",
        "    return structured_output"
      ],
      "metadata": {
        "id": "cPSeUF9PJZn-"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "structured_json = json_structure(converted_output)\n",
        "print(structured_json)"
      ],
      "metadata": {
        "id": "uwfpHJeFGWwo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "115d9ec3-6403-4b46-dd99-a7614e5bd65a"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'pages': [{'page_number': 1, 'tables': [{'columns': ['SESSION\\nDATE', 'SESSION\\nLOCATION', 'SESSION\\nCONDUCTED\\nBY NAME', 'ANC', 'CLASS', 'CLASS TYPE\\nSNCU', 'NBSU', 'PEOPLE\\nTRAINED', 'PHOTO\\nSENT'], 'rows': [['9/08/23', 'PNC ward', 'Mlo- Sarmila', '', '', '', '', '42', 'L'], ['11/8/23', 'PNC Ward', 'No.\\nReena\\nsapna', 'COO', '~', '', '', '', ''], ['12/8/23', 'PNC ward', 'Mo-Reeng', '', '', '', '00', '30', ''], ['14/8/2', 'PNC ward', 'Mo- Lagwanti\\nPinki, Reena', '', '', '', '', '48', ''], ['16/8/23', 'PMCward', 'Sharmib,\\nلسلف', '', '', '', '', '255er\\n46', ''], ['21/8/23', 'PNC ward', 'Sharmila\\nReang...', '', 'L', '', '', '45', ''], ['22/8/23', 'PNC ward', 'Sujata.', '', '', '', '', '42', ''], ['23/8/23', 'ANG', 'Safana.', '', '', '', '', '40', ''], ['24/8/23', 'New', 'vlo Kavita\\nReena', '', '', '', '', '40', ''], ['25/8/20', 'P.NC', 'Roly wants\\n180 Kavit', '45', ''], ['26/8/23', 'P.N.C.', 'Mo Lawanti\\nAnita.', '42', ''], ['30/8/23', 'PMC', 'Laranti\\nAle\\nPoonam', '327\\nчо', ''], ['31/8/27', 'PNC', 'N/- SujataKavita', '43', ''], ['1/09/23', 'PNC', 'Nh-Shamile', '', ''], ['', '', 'Lajwanti\\nPoonam', '383\\n38', ''], ['02/09/27', 'PMC', 'Na Nirmala\\n·Poo ham', '46', ''], ['04/9/23', 'Pnc', 'Sharmil\\nNo.\\nfornen.', '42', ''], ['4/9/23', 'PNC', 'W/o Reena', '36', '✓'], ['5/9/23', 'PNC', 'N/o Reena', '40', ''], ['5/9/23', 'PNC', 'Nlo Reenal\\nSharmila', '38', '']]}], 'form_fields': [{'Facility Name:': 'GH NNL M/garh'}]}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#restructuring structured_json to keep only required columns\n",
        "\n",
        "def restructure_json(original_json):\n",
        "    restructured_data = {'pages': []}\n",
        "\n",
        "    for page in original_json['pages']:\n",
        "        restructured_page = {'page_number': page['page_number'], 'tables': []}\n",
        "\n",
        "        for table in page['tables']:\n",
        "            restructured_table = {'columns': table['columns'][:3] + ['PeopleTrained'], 'rows': []}\n",
        "\n",
        "            for row in table['rows']:\n",
        "                session_date, session_location, conducted_by_name, *rest = row\n",
        "                people_trained = next((value for value in rest if value), None)\n",
        "\n",
        "                restructured_row = [session_date, session_location, conducted_by_name, people_trained]\n",
        "                restructured_table['rows'].append(restructured_row)\n",
        "\n",
        "            restructured_page['tables'].append(restructured_table)\n",
        "\n",
        "        for form_field, value in page['form_fields'][0].items():\n",
        "            restructured_page['form_fields'] = [{form_field: value}]\n",
        "\n",
        "        restructured_data['pages'].append(restructured_page)\n",
        "\n",
        "    return restructured_data\n",
        "\n",
        "# Example Usage:\n",
        "# Assuming you have the 'converted_output' as provided in your message\n",
        "restructured_json = restructure_json(structured_json)\n",
        "\n",
        "# Print the restructured data\n",
        "print(restructured_json)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBHklg89yli5",
        "outputId": "5ad025e7-52a7-40e9-8163-fd456b04e4ff"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'pages': [{'page_number': 1, 'tables': [{'columns': ['SESSION\\nDATE', 'SESSION\\nLOCATION', 'SESSION\\nCONDUCTED\\nBY NAME', 'PeopleTrained'], 'rows': [['9/08/23', 'PNC ward', 'Mlo- Sarmila', '42'], ['11/8/23', 'PNC Ward', 'No.\\nReena\\nsapna', 'COO'], ['12/8/23', 'PNC ward', 'Mo-Reeng', '00'], ['14/8/2', 'PNC ward', 'Mo- Lagwanti\\nPinki, Reena', '48'], ['16/8/23', 'PMCward', 'Sharmib,\\nلسلف', '255er\\n46'], ['21/8/23', 'PNC ward', 'Sharmila\\nReang...', 'L'], ['22/8/23', 'PNC ward', 'Sujata.', '42'], ['23/8/23', 'ANG', 'Safana.', '40'], ['24/8/23', 'New', 'vlo Kavita\\nReena', '40'], ['25/8/20', 'P.NC', 'Roly wants\\n180 Kavit', '45'], ['26/8/23', 'P.N.C.', 'Mo Lawanti\\nAnita.', '42'], ['30/8/23', 'PMC', 'Laranti\\nAle\\nPoonam', '327\\nчо'], ['31/8/27', 'PNC', 'N/- SujataKavita', '43'], ['1/09/23', 'PNC', 'Nh-Shamile', None], ['', '', 'Lajwanti\\nPoonam', '383\\n38'], ['02/09/27', 'PMC', 'Na Nirmala\\n·Poo ham', '46'], ['04/9/23', 'Pnc', 'Sharmil\\nNo.\\nfornen.', '42'], ['4/9/23', 'PNC', 'W/o Reena', '36'], ['5/9/23', 'PNC', 'N/o Reena', '40'], ['5/9/23', 'PNC', 'Nlo Reenal\\nSharmila', '38']]}], 'form_fields': [{'Facility Name:': 'GH NNL M/garh'}]}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#function to use restructured_json to make dictionary of required structure\n",
        "def structured_dictionary(final_json):\n",
        "    result = []\n",
        "\n",
        "    for page in final_json['pages']:\n",
        "        for table in page['tables']:\n",
        "            for row in table['rows']:\n",
        "                session_date, session_location, conducted_by_name, people_trained = row\n",
        "                entry_dict = {\n",
        "                    'SessionDate': session_date,\n",
        "                    'SessionLocation': session_location,\n",
        "                    'ConductedByName': conducted_by_name,\n",
        "                    'PeopleTrained': people_trained\n",
        "                }\n",
        "                result.append(entry_dict)\n",
        "\n",
        "    return result\n",
        "\n",
        "#using restructured_json to get final dictionary\n",
        "Dictionary = structured_dictionary(restructured_json)\n",
        "\n",
        "print(Dictionary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6Wspa251m-q",
        "outputId": "dedaf810-c66e-4e97-cb58-8e72ee5aaf59"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'SessionDate': '9/08/23', 'SessionLocation': 'PNC ward', 'ConductedByName': 'Mlo- Sarmila', 'PeopleTrained': '42'}, {'SessionDate': '11/8/23', 'SessionLocation': 'PNC Ward', 'ConductedByName': 'No.\\nReena\\nsapna', 'PeopleTrained': 'COO'}, {'SessionDate': '12/8/23', 'SessionLocation': 'PNC ward', 'ConductedByName': 'Mo-Reeng', 'PeopleTrained': '00'}, {'SessionDate': '14/8/2', 'SessionLocation': 'PNC ward', 'ConductedByName': 'Mo- Lagwanti\\nPinki, Reena', 'PeopleTrained': '48'}, {'SessionDate': '16/8/23', 'SessionLocation': 'PMCward', 'ConductedByName': 'Sharmib,\\nلسلف', 'PeopleTrained': '255er\\n46'}, {'SessionDate': '21/8/23', 'SessionLocation': 'PNC ward', 'ConductedByName': 'Sharmila\\nReang...', 'PeopleTrained': 'L'}, {'SessionDate': '22/8/23', 'SessionLocation': 'PNC ward', 'ConductedByName': 'Sujata.', 'PeopleTrained': '42'}, {'SessionDate': '23/8/23', 'SessionLocation': 'ANG', 'ConductedByName': 'Safana.', 'PeopleTrained': '40'}, {'SessionDate': '24/8/23', 'SessionLocation': 'New', 'ConductedByName': 'vlo Kavita\\nReena', 'PeopleTrained': '40'}, {'SessionDate': '25/8/20', 'SessionLocation': 'P.NC', 'ConductedByName': 'Roly wants\\n180 Kavit', 'PeopleTrained': '45'}, {'SessionDate': '26/8/23', 'SessionLocation': 'P.N.C.', 'ConductedByName': 'Mo Lawanti\\nAnita.', 'PeopleTrained': '42'}, {'SessionDate': '30/8/23', 'SessionLocation': 'PMC', 'ConductedByName': 'Laranti\\nAle\\nPoonam', 'PeopleTrained': '327\\nчо'}, {'SessionDate': '31/8/27', 'SessionLocation': 'PNC', 'ConductedByName': 'N/- SujataKavita', 'PeopleTrained': '43'}, {'SessionDate': '1/09/23', 'SessionLocation': 'PNC', 'ConductedByName': 'Nh-Shamile', 'PeopleTrained': None}, {'SessionDate': '', 'SessionLocation': '', 'ConductedByName': 'Lajwanti\\nPoonam', 'PeopleTrained': '383\\n38'}, {'SessionDate': '02/09/27', 'SessionLocation': 'PMC', 'ConductedByName': 'Na Nirmala\\n·Poo ham', 'PeopleTrained': '46'}, {'SessionDate': '04/9/23', 'SessionLocation': 'Pnc', 'ConductedByName': 'Sharmil\\nNo.\\nfornen.', 'PeopleTrained': '42'}, {'SessionDate': '4/9/23', 'SessionLocation': 'PNC', 'ConductedByName': 'W/o Reena', 'PeopleTrained': '36'}, {'SessionDate': '5/9/23', 'SessionLocation': 'PNC', 'ConductedByName': 'N/o Reena', 'PeopleTrained': '40'}, {'SessionDate': '5/9/23', 'SessionLocation': 'PNC', 'ConductedByName': 'Nlo Reenal\\nSharmila', 'PeopleTrained': '38'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "#to save restructured_json in json format\n",
        "def save_to_json(structured_data, filename='outputjson.json'):\n",
        "    with open(filename, 'w') as json_file:\n",
        "        json.dump(structured_data, json_file, indent=2)"
      ],
      "metadata": {
        "id": "B2BVLMqvyztf"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#restructured_json saved to outputjson.json\n",
        "save_to_json(Dictionary)"
      ],
      "metadata": {
        "id": "3ARaQbETJiUW"
      },
      "execution_count": 65,
      "outputs": []
    }
  ]
}